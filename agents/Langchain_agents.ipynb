{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ef6f457",
      "metadata": {
        "id": "2ef6f457"
      },
      "source": [
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.1.16 langchain-openai==0.0.8 langchain-community==0.0.32"
      ],
      "metadata": {
        "id": "BqkXk3tmP12h",
        "outputId": "0ad6ee3c-b1cc-4dd1-80cb-3f88db63bf32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BqkXk3tmP12h",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-checkpoint 4.0.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
            "google-adk 1.25.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-bigquery 3.40.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "db-dtypes 1.5.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "wheel 0.46.3 requires packaging>=24.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab4bf67",
      "metadata": {
        "id": "2ab4bf67"
      },
      "source": [
        "Connect to LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c892c928",
      "metadata": {
        "id": "c892c928"
      },
      "outputs": [],
      "source": [
        "# from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(openai_api_base = \"http://localhost:1234/v1\", openai_api_key = \"lm_studio\", model = \"qwen3-0.6b\",temperature=0.8,model_kwargs={\"seed\": 42}) #max_tokens=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912dec38",
      "metadata": {
        "id": "912dec38"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(openai_api_base = \"https://openrouter.ai/api/v1\", openai_api_key = \"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\", model = \"google/gemma-3-27b-it:free\",temperature=0.5) #max_tokens=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e0d1a1",
      "metadata": {
        "id": "53e0d1a1"
      },
      "outputs": [],
      "source": [
        "# from langchain_community.llms import Ollama\n",
        "# llm = Ollama(model=\"llama3.2:1b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35faadf7",
      "metadata": {
        "id": "35faadf7"
      },
      "source": [
        "Remove thinking Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b285f70",
      "metadata": {
        "id": "5b285f70"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_think_sections(text):\n",
        "    return re.sub(r\"<think>.*?</think>\", \"\", text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b238887b",
      "metadata": {
        "id": "b238887b"
      },
      "source": [
        "Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d42278a",
      "metadata": {
        "id": "0d42278a"
      },
      "outputs": [],
      "source": [
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dad9c45",
      "metadata": {
        "id": "2dad9c45"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.agents  import AgentType, initialize_agent, load_tools\n",
        "\n",
        "# set serpapi key\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"18031518456d0c1ad59a86282dd11d17ccc8bf8c20945e18396a54d5358a28f1\"\n",
        "\n",
        "# # local model\n",
        "# llm = ChatOpenAI(\n",
        "#     openai_api_base=\"http://localhost:1234/v1\",\n",
        "#     openai_api_key=\"lm_studio\",\n",
        "#     model=\"llama-3.2-1b-instruct\",\n",
        "#     temperature=0.9\n",
        "# )\n",
        "\n",
        "# tools\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) #bing-search, python_repl,terminal,arxiv,youtube-search\n",
        "\n",
        "# agent\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "# test\n",
        "print(agent.run(\"what the bitcoin price today and convert it into INR?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61cd7e7f",
      "metadata": {
        "id": "61cd7e7f"
      },
      "outputs": [],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e1d66a4",
      "metadata": {
        "id": "0e1d66a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "\n",
        "# llm = ChatOpenAI(\n",
        "#     openai_api_base=\"http://localhost:1234/v1\",\n",
        "#     openai_api_key=\"lm_studio\",\n",
        "#     model=\"llama-3.2-1b-instruct\",\n",
        "#     temperature=0.9\n",
        "# )\n",
        "\n",
        "# tools (wikipedia + math)\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "\n",
        "print(agent.run(\"In what year was the film Departed with Leonardo DiCaprio released?\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}